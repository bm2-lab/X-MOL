task_name="seq2seq"
submitter=" "
hdfs_path=" "
ugi=" "
hdfs_output=" "

slurm_train_files_dir=""
testdata_dir=""

### attention, this term need to be modified
vocab_path="./package/molecule_dict_zinc250k"
### attention, this term need to be modified
CONFIG_PATH="./package/ernie_zinc250k_config.json"

### attention, this term need to be modified
init_model="path_to_pre-trained_model/"

#CKPT_PATH='path_to_checkpoint_model/'


finetuning_task="seq2seq"
### attention, this term need to be modified
finetuning_data="path_to_task_data/zinc250k_gd/"
task_type="normal"
tokenizer="MolTokenizer"

queue=""
nodes=1

init_new_sent_embedding="True"
continuous_position="True"

two_stream="False"
random_noise="False"

warmup_proportion=0.1
lr_scheduler="linear_warmup_decay"
learning_rate=5e-5
# attention
epoch=100
# attention
valid_step=1000

batch_size=16
in_tokens="false"

max_src_len=256
max_tgt_len=256
tokenized_input="false"

weight_decay=0.01
label_smooth=0.0
mask_prob=0.0

max_dec_len=256
### attention, this term need to be modified
### for generation task, the decoding_strategy should be set as "sampling", which means random sampling is applied in the generation of new SMILES
### and "beam_search" is design for optimization task. is should be noticed that, in beam_search, only one result could be generated for one input
decoding_strategy="sampling"
#decoding_strategy="beam_search"
beam_size=4
### scale the probability in random sampling
T=-1.0
temperature=1.0
tgt_type_id=1
eos_idx=2
mask_idx=3
length_penalty=-1.0

random_seed=1
save_and_valid_by_epoch="false"
train_set="train.tsv"
dev_set="dev.tsv"
test_set="test.tsv"
#pred_set="pred.tsv"
do_train="false"
do_val="true"
do_test="false"
do_pred="false"
do_dec="true"
use_multi_gpu_test="true"
eval_script=""

export TOKENIZER="MolTokenizer"
export MODEL_PATH=${init_model}
export TASK_DATA_PATH=${finetuning_data}
